{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import functools\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "# Gene neighborhood\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "\n",
    "# GO analysis\n",
    "from goatools.base import download_go_basic_obo\n",
    "from goatools.base import download_ncbi_associations\n",
    "from goatools.obo_parser import GODag\n",
    "from goatools.anno.genetogo_reader import Gene2GoReader\n",
    "from goatools.goea.go_enrichment_ns import GOEnrichmentStudyNS\n",
    "\n",
    "\n",
    "# Ensembl ID to Entrez ID conversion\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "\n",
    "# GTF parser for Ensembl ID to gene symbol conversion\n",
    "from gtfparse import read_gtf\n",
    "\n",
    "\n",
    "# Word cloud\n",
    "import wordcloud\n",
    "import math\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gene Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneNeighborhood():\n",
    "    def __init__(self, expression_df, gtf_df_genes):\n",
    "        \n",
    "        self.dist = DistanceMetric.get_metric('euclidean')\n",
    "        self.df_dist = pd.DataFrame(self.dist.pairwise(expression_df), index=expression_df.index, columns = expression_df.index)\n",
    "        self.gtf_df_genes = gtf_df_genes\n",
    "        \n",
    "    def neighbors(self, gene, n_neighbors):\n",
    "        return set(self.df_dist[gene].sort_values().head(n_neighbors).index)\n",
    "\n",
    "    \n",
    "    def neighbors_df(self, gene, n_neighbors):\n",
    "        return pd.DataFrame(self.df_dist[gene].sort_values())\\\n",
    "        .merge(self.gtf_df_genes[['gene_id', 'gene_name']], \n",
    "               left_index=True, right_on='gene_id', how='left')\\\n",
    "        .rename(columns={gene:'distance'})\\\n",
    "        .set_index('gene_id')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembl ID to Entrez ID conversion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsemblIDToEntrezIDConverter():\n",
    "    def __init__(self):\n",
    "        with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "            df_a = ro.conversion.rpy2py(ro.r('''\n",
    "                                             library(org.Hs.eg.db)\n",
    "                                             as.data.frame(org.Hs.egENSEMBL)\n",
    "                                            '''))\n",
    "            self.entrez_ensembl_df = df_a.groupby(['ensembl_id']).first()\n",
    "    \n",
    "    def convert(self, gene_list_or_set):\n",
    "        \n",
    "        ensembl_id_df = pd.DataFrame(index = { re.sub(\"\\..*$\",\"\",x) for x in gene_list_or_set })\n",
    "        entrez_ids = set(ensembl_id_df.merge(self.entrez_ensembl_df, left_index=True, right_index=True)['gene_id'].astype(int))\n",
    "        return entrez_ids\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gene Ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entrez_ensembl_df():\n",
    "    with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "        df_a = ro.conversion.rpy2py(ro.r('''\n",
    "                                         library(org.Hs.eg.db)\n",
    "                                         as.data.frame(org.Hs.egENSEMBL)\n",
    "                                        '''))\n",
    "        entrez_ensembl_df = df_a.groupby(['ensembl_id']).first()\n",
    "        return entrez_ensembl_df\n",
    "\n",
    "\n",
    "class MyGeneOntologyAnalysis():\n",
    "    def __init__(self):\n",
    "        \n",
    "\n",
    "        obo_fname = download_go_basic_obo()\n",
    "        file_gene2go = download_ncbi_associations()\n",
    "        obodag = GODag(\"go-basic.obo\")\n",
    "\n",
    "        # Read NCBI's gene2go. Store annotations in a list of namedtuples\n",
    "        objanno = Gene2GoReader(file_gene2go, taxids=[9606])\n",
    "\n",
    "        # Get associations for each branch of the GO DAG (BP, MF, CC)\n",
    "        ns2assoc = objanno.get_ns2assc()\n",
    "\n",
    "        for nspc, id2gos in ns2assoc.items():\n",
    "            print(\"{NS} {N:,} annotated human genes\".format(NS=nspc, N=len(id2gos)))\n",
    "          \n",
    "        genes_with_annotation = set.union(*(set(x.keys()) for x in ns2assoc.values()))\n",
    "\n",
    "        \n",
    "        self.alpha = 0.05\n",
    "        \n",
    "        self.goeaobj = GOEnrichmentStudyNS(\n",
    "            genes_with_annotation, # List of human genes\n",
    "            ns2assoc, # geneid/GO associations\n",
    "            obodag, # Ontologies\n",
    "            propagate_counts = False,\n",
    "            alpha = self.alpha, # default significance cut-off\n",
    "            methods = ['fdr_bh']) # defult multipletest correction method\n",
    "        \n",
    "        \n",
    "\n",
    "    def goea_results_all(self, gene_set):\n",
    "        return self.goeaobj.run_study(gene_set)\n",
    "    \n",
    "    \n",
    "    def goea_results_significant(self, gene_set):\n",
    "        all_results = self.goea_results_all(gene_set)\n",
    "        return [r for r in all_results if r.p_fdr_bh < self.alpha]\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneOntologyWordCloud():\n",
    "    def __init__(self):\n",
    "        self.wc = wordcloud.WordCloud(colormap='rainbow', \n",
    "                             stopwords=['integral', 'component', 'of', 'process', 'activity', 'to'],\n",
    "                             collocations = True,\n",
    "                             ranks_only=True,\n",
    "                         )\n",
    "        \n",
    "    def gen_random_text(self):\n",
    "        # Generate a spacer between gene ontology terms\n",
    "        return ' '.join(''.join((random.choice('abcdefghijklmnopqrstuvwxyz') for _ in range(150))) for _ in range(3))\n",
    "        \n",
    "    def goea_to_text(self, goea_results):\n",
    "        # Generate a text concatenating GO term names, each name being repeated proportionally to the minus log of its pvalue\n",
    "        return ' '.join((''.join( ' ' + self.gen_random_text() + ' ' + x.name for _ in range(int((-10) * math.log2(x.p_uncorrected))))\n",
    "                for x in goea_results  if x.enrichment == 'e'))\n",
    "    \n",
    "    def generate_image(self, goea_results):\n",
    "        return self.wc.generate(self.goea_to_text(goea_results)).to_image()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gtf_genes_df():\n",
    "    try:\n",
    "        gtf_df_genes = pd.read_csv(\"gtf_df_genes.csv\")\n",
    "    except:\n",
    "        gtf_df = read_gtf(\"/ceph/genome/human/gencode25/gtf.CHR/_m/gencode.v25.annotation.gtf\")\n",
    "        gtf_df_genes = gtf_df[gtf_df[\"feature\"] == \"gene\"][['gene_id', 'gene_name']]\n",
    "        gtf_df_genes.to_csv(\"gtf_df_genes.csv\", index=None)\n",
    "        \n",
    "    return gtf_df_genes\n",
    "\n",
    "\n",
    "def fet(a, b, u):\n",
    "    # a, b, u are sets\n",
    "    # u is the universe\n",
    "    \n",
    "    yes_a = u.intersection(a)\n",
    "    yes_b = u.intersection(b)\n",
    "    no_a = u - a\n",
    "    no_b = u - b\n",
    "    \n",
    "    m = [[len(yes_a.intersection(yes_b)), len(no_a.intersection(yes_b)) ], \n",
    "                               [len(yes_a.intersection(no_b)), len(no_a.intersection(no_b))]]\n",
    "    return (*stats.fisher_exact(m), m)\n",
    "    #, m, len(yes_b)/len(u), len(yes_a)/len(u), len(yes_a.intersection(yes_b)) * len(no_a.intersection(no_b)) / (len(yes_a.intersection(no_b)) * len(no_a.intersection(yes_b)))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "class NeighborhoodGOWordCloud():\n",
    "    def __init__(self, n_neighbors):\n",
    "        \n",
    "        self.n_neighbors = n_neighbors\n",
    "        expression_df = pd.read_csv('../../_m/latent_variables.csv', index_col=0)\n",
    "        mucols = [x for x in expression_df.columns if 'mu' in x]\n",
    "        expression_df = expression_df[mucols]\n",
    "        \n",
    "        \n",
    "        # gene sets to test for enrichment\n",
    "        self.de_genes = set(pd.read_csv('/ceph/projects/v3_phase3_paper/analysis/differential_expression/_m/genes/diffExpr_szVctl_FDR05.txt',\n",
    "                      sep='\\t', usecols=[0], index_col=0).index)\n",
    "\n",
    "        self.twas_genes = set(pd.read_csv('/ceph/users/apua/projects/caudate_twas_reader/genes/_m/twas_significant_genes.csv')['gene_id'])\n",
    "\n",
    "        self.gwas_genes = set(pd.read_csv('/ceph/projects/v3_phase3_paper/inputs/gwas/PGC2_CLOZUK/table_s3/hg38/genes/_m/gwas_genes.csv')['gene_id'])\n",
    "     \n",
    "    \n",
    "        # universe of all genes\n",
    "        self.universe = set(expression_df.index[3:])\n",
    "\n",
    "        \n",
    "        \n",
    "        self.gtf_df_genes = get_gtf_genes_df()\n",
    "\n",
    "        self.gn = GeneNeighborhood(expression_df, self.gtf_df_genes)\n",
    "        \n",
    "        self.e2e = EnsemblIDToEntrezIDConverter()\n",
    "        self.mygoa = MyGeneOntologyAnalysis()\n",
    "        self.gowc = GeneOntologyWordCloud()\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "    def pipeline(self, gene_id, filename_prefix):\n",
    "        \n",
    "        #with open(\"%s_neighbors.txt\" % filename_prefix, \"wt\") as f:\n",
    "        #    for x in nn:\n",
    "        #        print(x, file=f)\n",
    "\n",
    "        self.gn.neighbors_df(gene_id, self.n_neighbors)\\\n",
    "        .to_csv(\"%s_neighbors.csv\" % filename_prefix)\n",
    "        \n",
    "        nn = self.gn.neighbors(gene_id, self.n_neighbors)\n",
    "        \n",
    "        \n",
    "        \n",
    "        sets_df = pd.DataFrame.from_records( ((xx[0], *fet(nn, xx[1], self.universe)) for xx in\n",
    "            [('gwas', self.gwas_genes),\n",
    "             ('twas', self.twas_genes),\n",
    "             ('de', self.de_genes),]), columns=['set', 'or', 'pvalue', 'm'])\n",
    "        sets_df.to_csv(\"%s_sets_enrichment.csv\" % filename_prefix)\n",
    "        print(sets_df)\n",
    "        \n",
    "        \n",
    "        \n",
    "        go_r = self.mygoa.goea_results_significant(self.e2e.convert(nn))\n",
    "        #self.mygoa.goeaobj.wr_txt(\"%s_go_enrichment.txt\" % filename_prefix, go_r)\n",
    "        self.mygoa.goeaobj.wr_tsv(\"%s_go_enrichment.tsv\" % filename_prefix, go_r)\n",
    "        p = self.gowc.generate_image(go_r)\n",
    "        p.save(\"%s_go_wordcloud.png\" % filename_prefix)\n",
    "        return p\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngowc = NeighborhoodGOWordCloud(250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngowc.pipeline('chr11:113412884-113415420(-)', 'DRD2_jucntion_5_7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngowc.pipeline('chr11:113414462-113415420(-)', 'DRD2_jucntion_5_6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(ngowc.gn.neighbors('chr11:113412884-113415420(-)', ngowc.n_neighbors))\\\n",
    ".intersection(set(ngowc.gn.neighbors('chr11:113414462-113415420(-)', ngowc.n_neighbors))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {z[0]:z[1]  for z in zip(ngowc.gtf_df_genes['gene_name'], ngowc.gtf_df_genes['gene_id'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in ['C4A', 'CSDC2', 'HCG4', 'REEP2', 'ZNF14', 'CNNM2', 'ENSA', 'PPTC7',\n",
    " 'NGEF', 'TDRD9', 'ZNF204P', 'ZNF391', 'BAG6', 'HIRIP3', 'IP6K3', 'NELFE',\n",
    " 'PRRC2A', 'TSNARE1', 'ZC3H7B', 'BNIP3L', 'BRD2', 'CACNA1I', 'CKB', 'ELFN1',\n",
    " 'LLGL1', 'PCCB', 'PHF1', 'PLPP5', 'PPM1M', 'SREBF2', 'TRMT61A', 'ZSCAN9',\n",
    " 'DRD2', 'SETD1A']:\n",
    "    try:\n",
    "        print(x)\n",
    "        ngowc.pipeline(d[x], x)\n",
    "    except:\n",
    "        print(\"Error processing %s\" % x)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
